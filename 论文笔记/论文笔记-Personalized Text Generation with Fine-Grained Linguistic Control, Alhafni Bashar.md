# Personalized Text Generation with Fine-Grained Linguistic Control（具有细粒度语言控制的个性化文本生成）

引入了一个全新的基准来训练生成模型，并评估其基于多种细粒度语言属性生成个性化文本的能力

不同用户输入相同的提示往往会得到结构类似的输出。以往的个性化生成方法聚焦于粗粒度，这篇论文聚焦于细粒度的个性化生成。

## 任务定义

### 输入输出

给定一组概括特定作者写作风格的风格属性，以及一个输入文本提示prompt，目标是生成符合所提供属性的文本。

| Feature Type  | Attribute                      |
| ------------- | ------------------------------ |
| Lexical       | 词数、句数、可读性评分（FKGL） |
| Morpho-Syntax | 词性标注（POS）、依存关系      |
| Discourse     | 修辞关系                       |

给定的风格属性组包含上面三种类型

其中

- 使用 FKGL score 衡量可读性
- POS Tags 统计文字中出现的各类词性的词数量
- 使用 ClearNLP 定义的 32 种依存关系，统计出每种句法关系的出现频率
- 使用 RST parser 统计每类修辞关系出现的频率，修辞关系包含补充、对比和归因。

提取作者A撰写的每个文本示例的上述语言特征后，对所有示例的每个特征值分别取平均值，从而得到作者向量ϕ(A)

### 评估指标

#### success rate

统计多少比例的属性落在对应的bin内，即预测成功

#### **Relative Improvement**

计算比起随机选择一个bin，模型的提升率？（**此处不大理解其作用**）

#### fluency

流畅度。将生成文本的语法错误数量与同一作者来源的真实语法错误数量进行比较。差别越小此得分越高

## 模型

### Baselines

1.在基准数据集上对 Pythia 模型进行了微调，但没有向模型输入任何属性。也就是说，输入仅为开发集或测试集中每个文本示例的第一个句子，要求模型预测接下来生成的句子。通过模型生成的预测评价该模型的能力，考察模型是否能够从文本本身中获取语言属性。

2.使用 OpenAI API 中的 GPT-3.5-turbo0613 模型

### Multi-Attribute Controlled Models

在论文中被称为 Prefix ，与Baseline相比，该模型在推理过程中将ϕ(A)添加到开发集或测试集中每个文本示例的第一个句子的前面。

## Experiments and Results

### 总体结果

1B Pythia Prefix 模型的表现优于其基线模型，且在所有指标中均表现最佳。

### Attribute Sensitivity Analysis（属性敏感性分析）

即使模型在整体上成功率很高，还需要确定它是否真正理解了每一个风格属性，对此需要进行属性敏感性分析。

挑选在训练集中至少有 1000 条样本的作者，仅修改ϕ(A)中某一个属性值，将修改后的ϕ‘(A)与原始首句拼接成输入，送入模型，评估结果是否符合新的ϕ‘(A)。

结果图呈现双峰甚至三峰特征，横轴是偏移量，纵轴是成功率。反映出模型在某些偏移量上依然有不错的效果，但在其他偏移量上比较差。

### Training Sample Efficacy

随着训练数据的减少，模型三个指标会下降。